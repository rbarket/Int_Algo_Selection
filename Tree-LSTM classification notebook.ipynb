{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e2d89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/barketr/.conda/envs/TreeLSTM_DGL/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-17 20:54:33.389597: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-17 20:54:34.893344: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-17 20:54:34.893407: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-17 20:54:34.897033: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-17 20:54:35.474327: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-17 20:54:39.168773: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import swifter\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "from torchmetrics.classification import BinaryPrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c60910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:\n",
      "GPU 0: Quadro RTX 8000\n",
      "GPU 1: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "if th.cuda.is_available():\n",
    "    print(\"Available GPUs:\")\n",
    "    for i in range(th.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {th.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPUs available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eee9c92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = th.device('cuda' if th.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acc77fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "seed = 1998\n",
    "th.manual_seed(seed)\n",
    "dgl.seed(seed)\n",
    "\n",
    "# Create a torch.Generator with the specified seed for random sampler\n",
    "generator = th.Generator()\n",
    "generator.manual_seed(seed)\n",
    "\n",
    "# If using a GPU, set the seed for GPU as well\n",
    "if th.cuda.is_available():\n",
    "    th.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415f8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIG = ['sin',\n",
    "'cos',\n",
    "'tan',\n",
    "'cot',\n",
    "'sec',\n",
    "'scs',\n",
    "'cosh',\n",
    "'sinh',\n",
    "'tanh',\n",
    "'acos',\n",
    "'asin',\n",
    "'atan',\n",
    "'acot',\n",
    "'asec',\n",
    "'ascs',\n",
    "'acosh',\n",
    "'asinh',\n",
    "'atanh']\n",
    "\n",
    "BIN_OP = ['add', 'sub', 'mul', 'div', 'pow']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b42d3",
   "metadata": {},
   "source": [
    "# Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3754f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc248028",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dataset/Train/BWD_train.json') as f:\n",
    "    bwd_train = json.load(f)\n",
    "with open('Dataset/Test/BWD_test.json') as f:\n",
    "    bwd_test = json.load(f)\n",
    "    \n",
    "with open('Dataset/Train/FWD_train.json') as f:\n",
    "    fwd_train = json.load(f)\n",
    "with open('Dataset/Test/FWD_test.json') as f:\n",
    "    fwd_test = json.load(f)\n",
    "\n",
    "with open('Dataset/Train/IBP_train.json') as f:\n",
    "    ibp_train = json.load(f)\n",
    "with open('Dataset/Test/IBP_test.json') as f:\n",
    "    ibp_test = json.load(f)\n",
    "    \n",
    "with open('Dataset/Train/SUB_train.json') as f:\n",
    "    sub_train = json.load(f)\n",
    "with open('Dataset/Test/SUB_test.json') as f:\n",
    "    sub_test = json.load(f)\n",
    "    \n",
    "with open('Dataset/Train/RISCH_train.json') as f:\n",
    "    risch_train = json.load(f)\n",
    "with open('Dataset/Test/RISCH_test.json') as f:\n",
    "    risch_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "810e6d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = bwd_train + fwd_train + ibp_train + sub_train + risch_train\n",
    "test_data = bwd_test + fwd_test + ibp_test + sub_test + risch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c488ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_data, columns=['integrand', 'prefix', 'integral', 'label'])\n",
    "df['graph_id'] = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "76bfaaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>integrand</th>\n",
       "      <th>prefix</th>\n",
       "      <th>integral</th>\n",
       "      <th>label</th>\n",
       "      <th>graph_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-2*x^3/(1+2*x)^2+3*x^2/(1+2*x)</td>\n",
       "      <td>[add, INT+, 2, add, mul, INT-, 2, mul, pow, x,...</td>\n",
       "      <td>x*(x^2+4*x+2)/(1+2*x)</td>\n",
       "      <td>[49, -1, -1, 49, 39, -1, 34, -1, -1, -1, -1, 43]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/x/(x+ln(x))*(1+x+x/cos(x)^2*(x+ln(x)))</td>\n",
       "      <td>[mul, pow, x, INT-, 1, mul, pow, add, x, ln, x...</td>\n",
       "      <td>tan(x)+ln(x+ln(x))</td>\n",
       "      <td>[-1, -1, 77, 107, -1, -1, 77, -1, -1, -1, -1, -1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/sin(x)^2*(-x*cos(x)+sin(x))*arctan(2)</td>\n",
       "      <td>[mul, pow, sin, x, INT-, 2, mul, add, mul, INT...</td>\n",
       "      <td>arctan(2)*x*csc(x)</td>\n",
       "      <td>[76, -1, 152, 106, 140, -1, 75, -1, -1, -1, -1...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x^2*sin(5)+2*x*(5+x)*sin(5)</td>\n",
       "      <td>[add, mul, pow, x, INT+, 2, sin, INT+, 5, mul,...</td>\n",
       "      <td>sin(5)*x^2*(5+x)</td>\n",
       "      <td>[63, -1, 71, 66, 71, -1, 71, -1, -1, -1, -1, 66]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/ln(x)*(2-x)-x/ln(x)-1/ln(x)^2*(2-x)</td>\n",
       "      <td>[add, mul, pow, ln, x, INT-, 1, add, INT+, 2, ...</td>\n",
       "      <td>(-x^2+2*x)/ln(x)</td>\n",
       "      <td>[69, -1, 69, 69, 61, -1, 61, -1, -1, -1, -1, -1]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  integrand  \\\n",
       "0           2-2*x^3/(1+2*x)^2+3*x^2/(1+2*x)   \n",
       "1  1/x/(x+ln(x))*(1+x+x/cos(x)^2*(x+ln(x)))   \n",
       "2   1/sin(x)^2*(-x*cos(x)+sin(x))*arctan(2)   \n",
       "3               x^2*sin(5)+2*x*(5+x)*sin(5)   \n",
       "4     1/ln(x)*(2-x)-x/ln(x)-1/ln(x)^2*(2-x)   \n",
       "\n",
       "                                              prefix               integral  \\\n",
       "0  [add, INT+, 2, add, mul, INT-, 2, mul, pow, x,...  x*(x^2+4*x+2)/(1+2*x)   \n",
       "1  [mul, pow, x, INT-, 1, mul, pow, add, x, ln, x...     tan(x)+ln(x+ln(x))   \n",
       "2  [mul, pow, sin, x, INT-, 2, mul, add, mul, INT...     arctan(2)*x*csc(x)   \n",
       "3  [add, mul, pow, x, INT+, 2, sin, INT+, 5, mul,...       sin(5)*x^2*(5+x)   \n",
       "4  [add, mul, pow, ln, x, INT-, 1, add, INT+, 2, ...       (-x^2+2*x)/ln(x)   \n",
       "\n",
       "                                               label  graph_id  \n",
       "0   [49, -1, -1, 49, 39, -1, 34, -1, -1, -1, -1, 43]         0  \n",
       "1  [-1, -1, 77, 107, -1, -1, 77, -1, -1, -1, -1, -1]         1  \n",
       "2  [76, -1, 152, 106, 140, -1, 75, -1, -1, -1, -1...         2  \n",
       "3   [63, -1, 71, 66, 71, -1, 71, -1, -1, -1, -1, 66]         3  \n",
       "4   [69, -1, 69, 69, 61, -1, 61, -1, -1, -1, -1, -1]         4  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea7350",
   "metadata": {},
   "source": [
    "# Remove all duplicates\n",
    "### Keep integers [-2,..,2] and replace rest with CONST for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a16fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function to replace integers with \"CONST\"\n",
    "def replace_int_with_C(L):\n",
    "    # L is a list of strings (prefix notation for expression)    \n",
    "    keep_list = list(range(-2,3)) # dont replace these integers with CONST\n",
    "    new_L = L.copy()\n",
    "        \n",
    "    for i in range(len(L)):\n",
    "        if L[i].isdigit():\n",
    "            \n",
    "            if int(L[i]) not in keep_list:\n",
    "                if len(L[i])==1: # 1 digit integers\n",
    "                    new_L[i] = 'CONST1'\n",
    "                elif len(L[i])==2: # 2 digit integers\n",
    "                    new_L[i] = 'CONST2'\n",
    "                else: # all other cases\n",
    "                    new_L[i] = 'CONST3'\n",
    "    return new_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aeb6f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prefix'] = df['prefix'].apply(replace_int_with_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b4f6990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>integrand</th>\n",
       "      <th>prefix</th>\n",
       "      <th>integral</th>\n",
       "      <th>label</th>\n",
       "      <th>graph_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-2*x^3/(1+2*x)^2+3*x^2/(1+2*x)</td>\n",
       "      <td>[add, INT+, 2, add, mul, INT-, 2, mul, pow, x,...</td>\n",
       "      <td>x*(x^2+4*x+2)/(1+2*x)</td>\n",
       "      <td>[49, -1, -1, 49, 39, -1, 34, -1, -1, -1, -1, 43]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/x/(x+ln(x))*(1+x+x/cos(x)^2*(x+ln(x)))</td>\n",
       "      <td>[mul, pow, x, INT-, 1, mul, pow, add, x, ln, x...</td>\n",
       "      <td>tan(x)+ln(x+ln(x))</td>\n",
       "      <td>[-1, -1, 77, 107, -1, -1, 77, -1, -1, -1, -1, -1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/sin(x)^2*(-x*cos(x)+sin(x))*arctan(2)</td>\n",
       "      <td>[mul, pow, sin, x, INT-, 2, mul, add, mul, INT...</td>\n",
       "      <td>arctan(2)*x*csc(x)</td>\n",
       "      <td>[76, -1, 152, 106, 140, -1, 75, -1, -1, -1, -1...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x^2*sin(5)+2*x*(5+x)*sin(5)</td>\n",
       "      <td>[add, mul, pow, x, INT+, 2, sin, INT+, CONST1,...</td>\n",
       "      <td>sin(5)*x^2*(5+x)</td>\n",
       "      <td>[63, -1, 71, 66, 71, -1, 71, -1, -1, -1, -1, 66]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/ln(x)*(2-x)-x/ln(x)-1/ln(x)^2*(2-x)</td>\n",
       "      <td>[add, mul, pow, ln, x, INT-, 1, add, INT+, 2, ...</td>\n",
       "      <td>(-x^2+2*x)/ln(x)</td>\n",
       "      <td>[69, -1, 69, 69, 61, -1, 61, -1, -1, -1, -1, -1]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1/x^2*(4*x^2-x+3)/(-ln(x)-3-3/x+4*x)</td>\n",
       "      <td>[mul, pow, x, INT-, 2, mul, add, mul, INT+, CO...</td>\n",
       "      <td>ln(ln(x)-(4*x^2-3*x-3)/x)</td>\n",
       "      <td>[88, -1, -1, 78, 88, -1, 94, -1, -1, -1, -1, -1]</td>\n",
       "      <td>99995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>3/2/x^2/(8*x+3)*(24*x^4-7*x^3-87*x^2-133*x-21)...</td>\n",
       "      <td>[add, mul, div, INT+, CONST1, INT+, 2, mul, po...</td>\n",
       "      <td>19/6*x+19/6-3/2*ln(exp(x+1)+(3*x^2-2*x-7)/(8*x...</td>\n",
       "      <td>[205, 229, -1, 175, 205, -1, 217, -1, -1, -1, ...</td>\n",
       "      <td>99996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1/3/x^2/(x^2-4*x+9)*(2*x^4-13*x^3+76*x^2-187*x...</td>\n",
       "      <td>[add, mul, div, INT+, 1, INT+, CONST1, mul, po...</td>\n",
       "      <td>1/3*ln(ln(x^2)-(3*x+4)/(x^2-4*x+9))-3/5*ln(ln(...</td>\n",
       "      <td>[185, -1, -1, 152, -1, -1, 193, -1, -1, -1, -1...</td>\n",
       "      <td>99997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>(-119400*x^8-3522810*x^7+19800*(-5+3*x)*x^7-22...</td>\n",
       "      <td>[add, mul, add, mul, INT-, CONST3, pow, x, INT...</td>\n",
       "      <td>-1/(10*x^3+198*x^2-29*x+2)*(10*x-1)*x^3*(-5+3*...</td>\n",
       "      <td>[-1, -1, -1, 175, -1, -1, 506, -1, -1, -1, -1,...</td>\n",
       "      <td>99998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>(-157/7-2/7/x+3/7*x-2/7/x^2)/(5*exp(x+1)+7)+(7...</td>\n",
       "      <td>[add, mul, add, div, INT-, CONST3, INT+, CONST...</td>\n",
       "      <td>-3/2*x-3/2-1/7*(75*x^4-45*exp(x+1)*x^3-340*x^3...</td>\n",
       "      <td>[-1, -1, -1, 268, -1, -1, 593, -1, -1, -1, -1,...</td>\n",
       "      <td>99999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               integrand  \\\n",
       "0                        2-2*x^3/(1+2*x)^2+3*x^2/(1+2*x)   \n",
       "1               1/x/(x+ln(x))*(1+x+x/cos(x)^2*(x+ln(x)))   \n",
       "2                1/sin(x)^2*(-x*cos(x)+sin(x))*arctan(2)   \n",
       "3                            x^2*sin(5)+2*x*(5+x)*sin(5)   \n",
       "4                  1/ln(x)*(2-x)-x/ln(x)-1/ln(x)^2*(2-x)   \n",
       "...                                                  ...   \n",
       "99995               1/x^2*(4*x^2-x+3)/(-ln(x)-3-3/x+4*x)   \n",
       "99996  3/2/x^2/(8*x+3)*(24*x^4-7*x^3-87*x^2-133*x-21)...   \n",
       "99997  1/3/x^2/(x^2-4*x+9)*(2*x^4-13*x^3+76*x^2-187*x...   \n",
       "99998  (-119400*x^8-3522810*x^7+19800*(-5+3*x)*x^7-22...   \n",
       "99999  (-157/7-2/7/x+3/7*x-2/7/x^2)/(5*exp(x+1)+7)+(7...   \n",
       "\n",
       "                                                  prefix  \\\n",
       "0      [add, INT+, 2, add, mul, INT-, 2, mul, pow, x,...   \n",
       "1      [mul, pow, x, INT-, 1, mul, pow, add, x, ln, x...   \n",
       "2      [mul, pow, sin, x, INT-, 2, mul, add, mul, INT...   \n",
       "3      [add, mul, pow, x, INT+, 2, sin, INT+, CONST1,...   \n",
       "4      [add, mul, pow, ln, x, INT-, 1, add, INT+, 2, ...   \n",
       "...                                                  ...   \n",
       "99995  [mul, pow, x, INT-, 2, mul, add, mul, INT+, CO...   \n",
       "99996  [add, mul, div, INT+, CONST1, INT+, 2, mul, po...   \n",
       "99997  [add, mul, div, INT+, 1, INT+, CONST1, mul, po...   \n",
       "99998  [add, mul, add, mul, INT-, CONST3, pow, x, INT...   \n",
       "99999  [add, mul, add, div, INT-, CONST3, INT+, CONST...   \n",
       "\n",
       "                                                integral  \\\n",
       "0                                  x*(x^2+4*x+2)/(1+2*x)   \n",
       "1                                     tan(x)+ln(x+ln(x))   \n",
       "2                                     arctan(2)*x*csc(x)   \n",
       "3                                       sin(5)*x^2*(5+x)   \n",
       "4                                       (-x^2+2*x)/ln(x)   \n",
       "...                                                  ...   \n",
       "99995                          ln(ln(x)-(4*x^2-3*x-3)/x)   \n",
       "99996  19/6*x+19/6-3/2*ln(exp(x+1)+(3*x^2-2*x-7)/(8*x...   \n",
       "99997  1/3*ln(ln(x^2)-(3*x+4)/(x^2-4*x+9))-3/5*ln(ln(...   \n",
       "99998  -1/(10*x^3+198*x^2-29*x+2)*(10*x-1)*x^3*(-5+3*...   \n",
       "99999  -3/2*x-3/2-1/7*(75*x^4-45*exp(x+1)*x^3-340*x^3...   \n",
       "\n",
       "                                                   label  graph_id  \n",
       "0       [49, -1, -1, 49, 39, -1, 34, -1, -1, -1, -1, 43]         0  \n",
       "1      [-1, -1, 77, 107, -1, -1, 77, -1, -1, -1, -1, -1]         1  \n",
       "2      [76, -1, 152, 106, 140, -1, 75, -1, -1, -1, -1...         2  \n",
       "3       [63, -1, 71, 66, 71, -1, 71, -1, -1, -1, -1, 66]         3  \n",
       "4       [69, -1, 69, 69, 61, -1, 61, -1, -1, -1, -1, -1]         4  \n",
       "...                                                  ...       ...  \n",
       "99995   [88, -1, -1, 78, 88, -1, 94, -1, -1, -1, -1, -1]     99995  \n",
       "99996  [205, 229, -1, 175, 205, -1, 217, -1, -1, -1, ...     99996  \n",
       "99997  [185, -1, -1, 152, -1, -1, 193, -1, -1, -1, -1...     99997  \n",
       "99998  [-1, -1, -1, 175, -1, -1, 506, -1, -1, -1, -1,...     99998  \n",
       "99999  [-1, -1, -1, 268, -1, -1, 593, -1, -1, -1, -1,...     99999  \n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe27c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any duplicates from dataset\n",
    "\n",
    "df[\"prefix\"] = df[\"prefix\"].transform(lambda k: tuple(k))  # transforming to tuple is much faster operation\n",
    "df.drop_duplicates(subset='prefix', inplace=True)\n",
    "df['prefix'] = df['prefix'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e39f8013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>integrand</th>\n",
       "      <th>prefix</th>\n",
       "      <th>integral</th>\n",
       "      <th>label</th>\n",
       "      <th>graph_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-2*x^3/(1+2*x)^2+3*x^2/(1+2*x)</td>\n",
       "      <td>[add, INT+, 2, add, mul, INT-, 2, mul, pow, x,...</td>\n",
       "      <td>x*(x^2+4*x+2)/(1+2*x)</td>\n",
       "      <td>[49, -1, -1, 49, 39, -1, 34, -1, -1, -1, -1, 43]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/x/(x+ln(x))*(1+x+x/cos(x)^2*(x+ln(x)))</td>\n",
       "      <td>[mul, pow, x, INT-, 1, mul, pow, add, x, ln, x...</td>\n",
       "      <td>tan(x)+ln(x+ln(x))</td>\n",
       "      <td>[-1, -1, 77, 107, -1, -1, 77, -1, -1, -1, -1, -1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/sin(x)^2*(-x*cos(x)+sin(x))*arctan(2)</td>\n",
       "      <td>[mul, pow, sin, x, INT-, 2, mul, add, mul, INT...</td>\n",
       "      <td>arctan(2)*x*csc(x)</td>\n",
       "      <td>[76, -1, 152, 106, 140, -1, 75, -1, -1, -1, -1...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x^2*sin(5)+2*x*(5+x)*sin(5)</td>\n",
       "      <td>[add, mul, pow, x, INT+, 2, sin, INT+, CONST1,...</td>\n",
       "      <td>sin(5)*x^2*(5+x)</td>\n",
       "      <td>[63, -1, 71, 66, 71, -1, 71, -1, -1, -1, -1, 66]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/ln(x)*(2-x)-x/ln(x)-1/ln(x)^2*(2-x)</td>\n",
       "      <td>[add, mul, pow, ln, x, INT-, 1, add, INT+, 2, ...</td>\n",
       "      <td>(-x^2+2*x)/ln(x)</td>\n",
       "      <td>[69, -1, 69, 69, 61, -1, 61, -1, -1, -1, -1, -1]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  integrand  \\\n",
       "0           2-2*x^3/(1+2*x)^2+3*x^2/(1+2*x)   \n",
       "1  1/x/(x+ln(x))*(1+x+x/cos(x)^2*(x+ln(x)))   \n",
       "2   1/sin(x)^2*(-x*cos(x)+sin(x))*arctan(2)   \n",
       "3               x^2*sin(5)+2*x*(5+x)*sin(5)   \n",
       "4     1/ln(x)*(2-x)-x/ln(x)-1/ln(x)^2*(2-x)   \n",
       "\n",
       "                                              prefix               integral  \\\n",
       "0  [add, INT+, 2, add, mul, INT-, 2, mul, pow, x,...  x*(x^2+4*x+2)/(1+2*x)   \n",
       "1  [mul, pow, x, INT-, 1, mul, pow, add, x, ln, x...     tan(x)+ln(x+ln(x))   \n",
       "2  [mul, pow, sin, x, INT-, 2, mul, add, mul, INT...     arctan(2)*x*csc(x)   \n",
       "3  [add, mul, pow, x, INT+, 2, sin, INT+, CONST1,...       sin(5)*x^2*(5+x)   \n",
       "4  [add, mul, pow, ln, x, INT-, 1, add, INT+, 2, ...       (-x^2+2*x)/ln(x)   \n",
       "\n",
       "                                               label  graph_id  \n",
       "0   [49, -1, -1, 49, 39, -1, 34, -1, -1, -1, -1, 43]         0  \n",
       "1  [-1, -1, 77, 107, -1, -1, 77, -1, -1, -1, -1, -1]         1  \n",
       "2  [76, -1, 152, 106, 140, -1, 75, -1, -1, -1, -1...         2  \n",
       "3   [63, -1, 71, 66, 71, -1, 71, -1, -1, -1, -1, 66]         3  \n",
       "4   [69, -1, 69, 69, 61, -1, 61, -1, -1, -1, -1, -1]         4  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c840f9f",
   "metadata": {},
   "source": [
    "# Convert the length of each sub-algo to binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f2bab9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_binary(L):\n",
    "    lowest_positive = min(filter(lambda x: x > 0, L), default=None)\n",
    "    return [1 if x == lowest_positive else 0 for x in L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f84f4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(change_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a2c68df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
       "1    [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
       "2    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
       "3    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "4    [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1838ffaf",
   "metadata": {},
   "source": [
    "# Plot counts of each sub-algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9258d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {\n",
    "    'default': 0, \n",
    "    'ddivides': 0, \n",
    "    'risch': 0,\n",
    "    'norman': 0,\n",
    "    'trager': 0,\n",
    "    'meijerg': 0, \n",
    "    'elliptic': 0, \n",
    "    'lookup': 0,\n",
    "    'gosper': 0,\n",
    "    'parts': 0,\n",
    "    'pseudoelliptic': 0,\n",
    "    'parallelrisch': 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d81ba4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for L in df['label']:\n",
    "    if L[0]==1:\n",
    "        count['default'] += 1\n",
    "    if L[1]==1:\n",
    "        count['ddivides'] += 1\n",
    "    if L[2]==1:\n",
    "        count['parts'] += 1    \n",
    "    if L[3]==1:\n",
    "        count['risch'] += 1\n",
    "    if L[4]==1:\n",
    "        count['norman'] += 1\n",
    "    if L[5]==1:\n",
    "        count['trager'] += 1\n",
    "    if L[6]==1:\n",
    "        count['parallelrisch'] += 1\n",
    "    if L[7]==1:\n",
    "        count['meijerg'] += 1\n",
    "    if L[8]==1:\n",
    "        count['elliptic'] += 1\n",
    "    if L[9]==1:\n",
    "        count['pseudoelliptic'] += 1\n",
    "    if L[10]==1:\n",
    "        count['lookup'] += 1\n",
    "    if L[11]==1:\n",
    "        count['gosper'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3df1f6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': 49046,\n",
       " 'ddivides': 16094,\n",
       " 'risch': 44875,\n",
       " 'norman': 26239,\n",
       " 'trager': 1918,\n",
       " 'meijerg': 928,\n",
       " 'elliptic': 112,\n",
       " 'lookup': 367,\n",
       " 'gosper': 13932,\n",
       " 'parts': 22224,\n",
       " 'pseudoelliptic': 469,\n",
       " 'parallelrisch': 31376}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b23061e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = sns.barplot(x=list(count.keys()), y=list(count.values()))\n",
    "plt.set_title(\"Distribution of Sub-Algorithm use\")\n",
    "for item in plt.get_xticklabels():\n",
    "    item.set_rotation(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a1146",
   "metadata": {},
   "source": [
    "# Create Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e2573b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [word for expr in df['prefix'] for word in expr[0]]\n",
    "vocab_size = len(set(word_list)) # include all words\n",
    "x_size = round(1.6*9) # https://ai.stackexchange.com/questions/28564/how-to-determine-the-embedding-size#:~:text=If%20we're%20in%20a,and%20no%20less%20than%20600.\n",
    "max_len = max([len(word[1]) for word in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "44abf45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token='OOV')\n",
    "tokenizer.fit_on_texts(df['prefix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "afbeccb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OOV': 1,\n",
       " 'int+': 2,\n",
       " 'mul': 3,\n",
       " 'x': 4,\n",
       " 'add': 5,\n",
       " 'int-': 6,\n",
       " 'const1': 7,\n",
       " 'pow': 8,\n",
       " '1': 9,\n",
       " '2': 10,\n",
       " 'const2': 11,\n",
       " 'div': 12,\n",
       " 'const3': 13,\n",
       " 'exp': 14,\n",
       " 'ln': 15,\n",
       " 'cos': 16,\n",
       " 'sin': 17,\n",
       " 'tan': 18,\n",
       " 'cosh': 19,\n",
       " 'sinh': 20,\n",
       " 'tanh': 21,\n",
       " 'atan': 22,\n",
       " 'acos': 23,\n",
       " 'asin': 24,\n",
       " 'asinh': 25,\n",
       " 'atanh': 26,\n",
       " 'acosh': 27,\n",
       " 'pi': 28,\n",
       " 'abs': 29,\n",
       " 'complex': 30,\n",
       " 'i': 31,\n",
       " 'cot': 32,\n",
       " 'acot': 33,\n",
       " '0': 34}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f9d283",
   "metadata": {},
   "source": [
    "# Make dataframe of edge list and graph list from the expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7e7b7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_df(row):\n",
    "    \n",
    "    # reverse expression list to prepare for parsing\n",
    "    rev_expr = list(reversed(row['prefix']))\n",
    "    \n",
    "    # attach ID to each node and clean\n",
    "    node_id_list = [x for x in range(len(rev_expr))]\n",
    "\n",
    "    expr = [x for x in rev_expr if x != 'INT+']\n",
    "    expr = [x for x in expr if x != 'INT-']\n",
    "    expr = [[i, x] for i,x in zip(node_id_list, expr)]\n",
    "    \n",
    "    # create the edge list\n",
    "    stack = []\n",
    "    edge_list = []\n",
    "    bin_ops = ['add', 'sub', 'mul', 'div', 'pow']\n",
    "\n",
    "    # parse through the expression and point children to parent\n",
    "    # print(row)\n",
    "    for token in expr:\n",
    "        if token[1] in [\"CONST1\", \"CONST2\", \"CONST3\", '-2', '-1', '0', '1', '2']:  # CHANGE IF CONSTANTS CHANGE\n",
    "            stack.append(token[0])\n",
    "        elif token[1] == 'x' or token[1] == 'Pi' or token[1] == 'E' or token[1] == 'I':\n",
    "            stack.append(token[0])\n",
    "        elif token[1] in bin_ops:\n",
    "            edge_list.append([stack.pop(), token[0]])\n",
    "            edge_list.append([stack.pop(), token[0]])\n",
    "            stack.append(token[0])\n",
    "        else:  # unary operator\n",
    "            edge_list.append([stack.pop(), token[0]])\n",
    "            stack.append(token[0])\n",
    "    \n",
    "    edge_df = pd.DataFrame(edge_list, columns=['src', 'dst'])\n",
    "    edge_df['graph_id'] = [row['graph_id']]*len(edge_df)\n",
    "    \n",
    "    # create node features\n",
    "    node_df = pd.DataFrame(expr, columns=['node_id', 'value'])\n",
    "    node_df['graph_id'] = [row['graph_id']]*len(node_df)  # id\n",
    "    vals = tokenizer.texts_to_sequences(node_df['value'])  # word\n",
    "    feats = th.tensor([x for sublist in vals for x in sublist])\n",
    "    prop_df = pd.DataFrame([[row.graph_id, len(expr), feats, th.as_tensor(row.label)]], \n",
    "                           columns=['graph_id', 'num_nodes', 'features', 'label'])\n",
    "    \n",
    "    return edge_df, prop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "77d4caa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 92814/92814 [01:47<00:00, 863.81it/s] \n"
     ]
    }
   ],
   "source": [
    "# Takes close to 3 mins on 170k examples\n",
    "\n",
    "graph_specs = df.swifter.apply(make_graph_df, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7b1c639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [x[0] for x in graph_specs]\n",
    "graphs= [x[1] for x in graph_specs]\n",
    "\n",
    "edge_df = pd.concat(edges).reset_index(drop=True)\n",
    "graph_df = pd.concat(graphs).reset_index(drop=True)\n",
    "graph_df.set_index('graph_id', drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb37e8cd",
   "metadata": {},
   "source": [
    "# Graph Classification Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4bbe99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataset(DGLDataset):\n",
    "    def __init__(self, sub_algo, edge_df, graph_df):        \n",
    "        self.sub_algo = sub_algo\n",
    "        self.edges = edge_df\n",
    "        self.properties = graph_df\n",
    "        super().__init__(name=\"integration\")\n",
    "\n",
    "    def process(self):\n",
    "        # edges = edge_df\n",
    "        # properties = graph_df\n",
    "        self.graphs = []\n",
    "        self.labels = []\n",
    "        algo_dict = {'default': 0, \n",
    "                    'derivativedivides': 1, \n",
    "                    'parts': 2,\n",
    "                    'risch': 3,\n",
    "                    'norman': 4,\n",
    "                    'trager': 5,\n",
    "                    'parallelrisch': 6,\n",
    "                    'meijerg': 7, \n",
    "                    'elliptic': 8,\n",
    "                    'pseudoelliptic':9, \n",
    "                    'lookup': 10,\n",
    "                    'gosper': 11}\n",
    "\n",
    "        # Create a graph for each graph ID from the edges table.\n",
    "        # First process the properties table into two dictionaries with graph IDs as keys.\n",
    "        # The label and number of nodes are values.\n",
    "        label_dict = {}\n",
    "        num_nodes_dict = {}\n",
    "        for _, row in self.properties.iterrows():\n",
    "            label_dict[row[\"graph_id\"]] = row[\"label\"][algo_dict[self.sub_algo]]\n",
    "            num_nodes_dict[row[\"graph_id\"]] = row[\"num_nodes\"]\n",
    "\n",
    "        # For the edges, first group the table by graph IDs.\n",
    "        edges_group = self.edges.groupby(\"graph_id\")\n",
    "        edge_IDs = edges_group.groups\n",
    "\n",
    "        # For each graph ID...\n",
    "        graph_IDs = list(set(self.properties['graph_id']))\n",
    "        for graph_id in graph_IDs:\n",
    "            \n",
    "            if graph_id in edge_IDs:\n",
    "                # Find the edges as well as the number of nodes and its label.\n",
    "                edges_of_id = edges_group.get_group(graph_id)\n",
    "                src = edges_of_id[\"src\"]  # .to_numpy()\n",
    "                dst = edges_of_id[\"dst\"]  # .to_numpy()\n",
    "                num_nodes = num_nodes_dict[graph_id]                \n",
    "\n",
    "                # Create a graph and add it to the list of graphs and labels.\n",
    "                g = dgl.graph((list(src), list(dst)), num_nodes=num_nodes)\n",
    "            \n",
    "            else:  # graph is a single node with no edges\n",
    "                \n",
    "                assert self.properties.loc[graph_id]['num_nodes'] == 1, \"graph is not a single node\"               \n",
    "                g = dgl.DGLGraph()\n",
    "                g.add_nodes(1)\n",
    "                \n",
    "            label = label_dict[graph_id]    \n",
    "            props = self.properties['features'].loc[graph_id]\n",
    "            g.ndata['features'] = props \n",
    "            g.ndata['is_root'] = th.tensor( [0]*(len(props)-1) + [1], dtype=th.bool )\n",
    "            self.graphs.append(g)\n",
    "            self.labels.append(label)\n",
    "        self.dim_nfeats = 1\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ab967",
   "metadata": {},
   "source": [
    "# DataLoader for mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4e8d3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(dataset, size=128):\n",
    "\n",
    "    train_dataloader = GraphDataLoader(\n",
    "        dataset, \n",
    "        batch_size=size, \n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2605eb29",
   "metadata": {},
   "source": [
    "# TreeLSTM cell class and TreeLSTM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e44752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeLSTMCell(nn.Module):\n",
    "    def __init__(self, x_size, h_size):\n",
    "        super(TreeLSTMCell, self).__init__()\n",
    "        self.h_size = h_size\n",
    "        self.W_iou = nn.Linear(x_size, 3 * h_size, bias=False)\n",
    "        self.U_iou = nn.Linear(2 * h_size, 3 * h_size, bias=False)\n",
    "        self.b_iou = nn.Parameter(th.zeros(1, 3 * h_size))\n",
    "        self.U_f = nn.Linear(2 * h_size, 2 * h_size)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        return {'h': edges.src['h'], 'c': edges.src['c']}\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        # concatenate h_jl for equation (1), (2), (3), (4)\n",
    "        h_cat = nodes.mailbox['h'].view(nodes.mailbox['h'].size(0), -1)\n",
    "        \n",
    "        padding_hs = 2 - nodes.mailbox['h'].size(1)\n",
    "        padding = h_cat.new_zeros(size=(nodes.mailbox['h'].size(0), padding_hs * self.h_size))\n",
    "        h_cat = th.cat((h_cat, padding), dim=1)\n",
    "        # equation (2)\n",
    "        f = th.sigmoid(self.U_f(h_cat)).view(nodes.mailbox['h'].size(0), 2, self.h_size)\n",
    "        # second term of equation (5)       \n",
    "        padding_cs = 2 - nodes.mailbox['c'].size(1)\n",
    "        padding = h_cat.new_zeros(size=(nodes.mailbox['c'].size(0), padding_cs, self.h_size))\n",
    "        \n",
    "        c = th.cat((nodes.mailbox['c'], padding), dim=1)\n",
    "        c = th.sum(f * c, 1)\n",
    "        \n",
    "        c = th.sum(f * nodes.mailbox['c'], 1)\n",
    "        return {'iou': nodes.data['iou'] + self.U_iou(h_cat), 'c': c}\n",
    "\n",
    "    def apply_node_func(self, nodes):\n",
    "        # equation (1), (3), (4)\n",
    "        iou = nodes.data['iou'] + self.b_iou\n",
    "        i, o, u = th.chunk(iou, 3, 1)\n",
    "        i, o, u = th.sigmoid(i), th.sigmoid(o), th.tanh(u)\n",
    "        # equation (5)\n",
    "        c = i * u + nodes.data['c']\n",
    "        # equation (6)\n",
    "        h = o * th.tanh(c)\n",
    "        return {'h' : h, 'c' : c}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "477160c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_vocabs,\n",
    "                 x_size,\n",
    "                 h_size,\n",
    "                 dropout):\n",
    "        super(TreeLSTM, self).__init__()\n",
    "        self.x_size = x_size\n",
    "        self.embedding = nn.Embedding(num_vocabs, x_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.cell1 = TreeLSTMCell(x_size, h_size)\n",
    "        self.cell2 = TreeLSTMCell(h_size, h_size)\n",
    "        self.linear1 = nn.Linear(h_size, 9)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(9, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, batch, h, c):\n",
    "        \"\"\"Compute tree-lstm prediction given a batch.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : dgl.data.SSTBatch\n",
    "            The data batch.\n",
    "        h : Tensor\n",
    "            Initial hidden state.\n",
    "        c : Tensor\n",
    "            Initial cell state.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        logits : Tensor\n",
    "            The prediction of each node.\n",
    "        \"\"\"\n",
    "        # to heterogenous graph\n",
    "        # g = dgl.graph(batch.edges())\n",
    "        # feed embedding\n",
    "        embeds = self.embedding(batch.ndata['features'])\n",
    "        batch.ndata['iou'] = self.cell1.W_iou(self.dropout(embeds))\n",
    "        batch.ndata['h'] = h\n",
    "        batch.ndata['c'] = c\n",
    "        # propagate 1\n",
    "        dgl.prop_nodes_topo(batch,\n",
    "                            message_func=self.cell1.message_func,\n",
    "                            reduce_func=self.cell1.reduce_func,\n",
    "                            apply_node_func=self.cell1.apply_node_func)\n",
    "        # propagate 2\n",
    "        dgl.prop_nodes_topo(batch,\n",
    "                            message_func=self.cell2.message_func,\n",
    "                            reduce_func=self.cell2.reduce_func,\n",
    "                            apply_node_func=self.cell2.apply_node_func)\n",
    "        # compute logits\n",
    "        h = self.dropout(batch.ndata.pop('h'))\n",
    "        logits = self.linear1(h)  # only get root nodes for graph classification\n",
    "        logits = self.ReLU(logits)\n",
    "        logits = self.linear2(logits)        \n",
    "        logits = self.sigmoid(logits)\n",
    "        logits = logits[batch.ndata['is_root']]  # return only root node predictions\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e028dc1",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5348f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables:\n",
    "\n",
    "word_list = list(set([word for expr in train_data for word in expr[1]]))\n",
    "vocab_size = len(set(word_list)) # include all words\n",
    "\n",
    "input_size = 1  # Input feature size\n",
    "hidden_size = 124  # Hidden state size\n",
    "num_classes = 2  # Binary classification\n",
    "x_size = round(1.6*9) # https://ai.stackexchange.com/questions/28564/how-to-determine-the-embedding-size#:~:text=If%20we're%20in%20a,and%20no%20less%20than%20600.\n",
    "dropout = 0.4\n",
    "\n",
    "epochs = 15\n",
    "learn_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f348e8be",
   "metadata": {},
   "source": [
    "# Training Loop and Test Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e38bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader):\n",
    "    model = TreeLSTM(vocab_size,\n",
    "                     x_size, \n",
    "                     hidden_size,\n",
    "                     dropout\n",
    "                    )\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = th.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        output_list = []\n",
    "        label_list = []\n",
    "        accuracy = BinaryAccuracy().to(device)\n",
    "        precision = BinaryPrecision().to(device)\n",
    "        for batched_graph, labels in data_loader:\n",
    "            batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "            n = batched_graph.num_nodes()\n",
    "            h = th.zeros((n, hidden_size)).to(device)\n",
    "            c = th.zeros((n, hidden_size)).to(device)            \n",
    "            output = model(batched_graph, h, c)\n",
    "            output = output.to(th.float)\n",
    "            loss = criterion(output.view(-1, 1), labels.to(th.float).view(-1, 1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                        \n",
    "            output_list.extend(output)\n",
    "            label_list.extend(labels)\n",
    "              \n",
    "        output = th.round(th.tensor(output_list))\n",
    "        label = th.tensor(label_list)\n",
    "        print(f'epoch: {epoch}, train acc: {accuracy(output, label)}, train pre: {precision(output, label)}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test(model, data, is_loader=True):\n",
    "    # model: Trained Pytorch DGL model\n",
    "    # data: can either be a data_loader or a DGL graph. If DGL graph, set is_loader to False\n",
    "    # is_loader: specify whether the data is a data_loader. Set false if passing a graph.\n",
    "    \n",
    "    output_list = []\n",
    "    label_list = []\n",
    "    accuracy = BinaryAccuracy().to(device)\n",
    "    precision = BinaryPrecision().to(device)\n",
    "    \n",
    "    if is_loader:\n",
    "        for batched_graph, labels in data:\n",
    "            batched_graph, labels = batched_graph.to(device), labels.to(device) \n",
    "            n = batched_graph.num_nodes()\n",
    "            h = th.zeros((n, hidden_size)).to(device)\n",
    "            c = th.zeros((n, hidden_size)).to(device)\n",
    "            with th.no_grad():\n",
    "                model.eval()    \n",
    "                output = model(batched_graph, h, c)\n",
    "            \n",
    "            output_list.extend(output)\n",
    "            label_list.extend(labels)\n",
    "        \n",
    "    output = th.round(th.tensor(output_list))\n",
    "    label = th.tensor(label_list)\n",
    "    print(f'test acc: {accuracy(output, label)}, test pre: {precision(output, label)}')\n",
    "    return [data.item() for data in output_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49584f39",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4cd86c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(dataset, folds=5):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    total_acc = []\n",
    "    total_pre = []    \n",
    "    best_acc = 0\n",
    "    best_model = None \n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(dataset.graphs, dataset.labels)):  # 5 folds means test data is 20%\n",
    "        print(f'Fold {fold}')\n",
    "        \n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        test_sampler = SubsetRandomSampler(val_idx)\n",
    "        \n",
    "        train_dataloader = GraphDataLoader(\n",
    "        dataset, \n",
    "        sampler=train_sampler, \n",
    "        batch_size=256, \n",
    "        drop_last=False\n",
    "        )\n",
    "\n",
    "        test_dataloader = GraphDataLoader(\n",
    "            dataset, \n",
    "            sampler=test_sampler, \n",
    "            batch_size=256, \n",
    "            drop_last=False\n",
    "        )        \n",
    "            \n",
    "        model = TreeLSTM(vocab_size,\n",
    "                        x_size, \n",
    "                        hidden_size, \n",
    "                        num_classes,\n",
    "                        dropout\n",
    "                        )\n",
    "        model.to(device)\n",
    "        \n",
    "        optimizer = th.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "        criterion = nn.BCELoss()\n",
    "        \n",
    "        # Training        \n",
    "        for epoch in range(epochs):\n",
    "            output_list = []\n",
    "            label_list = []\n",
    "            \n",
    "            accuracy = BinaryAccuracy().to(device)\n",
    "            precision = BinaryPrecision().to(device)            \n",
    "            for batched_graph, labels in train_dataloader:\n",
    "                batched_graph, labels = batched_graph.to(device), labels.to(device)\n",
    "                n = batched_graph.num_nodes()\n",
    "                h = th.zeros((n, hidden_size)).to(device)\n",
    "                c = th.zeros((n, hidden_size)).to(device)            \n",
    "                output = model(batched_graph, h, c)\n",
    "                output = output.to(th.float)\n",
    "                loss = criterion(output.view(-1, 1), labels.to(th.float).view(-1, 1))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                            \n",
    "                output_list.extend(output)\n",
    "                label_list.extend(labels)\n",
    "                \n",
    "            output = th.round(th.tensor(output_list))\n",
    "            label = th.tensor(label_list)\n",
    "            acc, pre = accuracy(output, label), precision(output, label)\n",
    "            print(f'epoch: {epoch}, train acc: {acc:.4f}, train pre: {pre:.4f}')\n",
    "        \n",
    "        # testing\n",
    "        with th.no_grad():\n",
    "            model.eval()\n",
    "            output_list = []\n",
    "            label_list = []\n",
    "            accuracy = BinaryAccuracy().to(device)\n",
    "            precision = BinaryPrecision().to(device)\n",
    "            for batched_graph, labels in test_dataloader:\n",
    "                batched_graph, labels = batched_graph.to(device), labels.to(device) \n",
    "                n = batched_graph.num_nodes()\n",
    "                h = th.zeros((n, hidden_size)).to(device)\n",
    "                c = th.zeros((n, hidden_size)).to(device)\n",
    "                \n",
    "                output = model(batched_graph, h, c)\n",
    "            \n",
    "                output_list.extend(output)\n",
    "                label_list.extend(labels)\n",
    "            \n",
    "            output = th.round(th.tensor(output_list))\n",
    "            label = th.tensor(label_list)\n",
    "            acc, pre = accuracy(output, label), precision(output, label)\n",
    "            print(f'Testing acc: {acc:.4f}, Testing pre: {pre:.4f}')\n",
    "            total_acc.append(acc)\n",
    "            total_pre.append(pre)\n",
    "            \n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model = model            \n",
    "    \n",
    "    mean_acc = sum(total_acc) / folds\n",
    "    mean_pre = sum(total_pre) / folds\n",
    "    std_acc = th.tensor(total_acc).std().item()\n",
    "    std_pre = th.tensor(total_pre).std().item()\n",
    "    \n",
    "    print(f\"\\nMean Validation Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"\\nMean Validation Precision: {mean_pre:.4f} ± {std_pre:.4f}\\n\")        \n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e7dd8",
   "metadata": {},
   "source": [
    "# Train all sub-algos in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c333dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_algos = [\"default\",\n",
    "\"derivativedivides\",\n",
    "\"parts\",\n",
    "\"risch\",\n",
    "\"norman\",\n",
    "\"trager\",\n",
    "\"parallelrisch\",\n",
    "\"meijerg\",\n",
    "\"gosper\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a90773f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING FOR default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/barketr/.conda/envs/TreeLSTM_DGL/lib/python3.10/site-packages/dgl/heterograph.py:92: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning(\n",
      "/home/barketr/.conda/envs/TreeLSTM_DGL/lib/python3.10/site-packages/dgl/core.py:82: DGLWarning: The input graph for the user-defined edge function does not contain valid edges\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train acc: 0.7215075492858887, train pre: 0.7081210017204285\n",
      "epoch: 1, train acc: 0.7159911394119263, train pre: 0.7005622982978821\n",
      "epoch: 2, train acc: 0.7336392998695374, train pre: 0.745270848274231\n",
      "epoch: 3, train acc: 0.7402116060256958, train pre: 0.7484158873558044\n",
      "epoch: 4, train acc: 0.7590342164039612, train pre: 0.7676934003829956\n",
      "epoch: 5, train acc: 0.7792574167251587, train pre: 0.7829093337059021\n",
      "epoch: 6, train acc: 0.7896976470947266, train pre: 0.792874276638031\n",
      "epoch: 7, train acc: 0.7995237708091736, train pre: 0.8066036701202393\n",
      "epoch: 8, train acc: 0.8073674440383911, train pre: 0.8145957589149475\n",
      "epoch: 9, train acc: 0.8131747245788574, train pre: 0.8202755451202393\n",
      "epoch: 10, train acc: 0.8195422887802124, train pre: 0.8253188133239746\n",
      "epoch: 11, train acc: 0.8240567445755005, train pre: 0.8303712010383606\n",
      "epoch: 12, train acc: 0.8286357522010803, train pre: 0.8352519869804382\n",
      "epoch: 13, train acc: 0.8342383503913879, train pre: 0.8407052755355835\n",
      "epoch: 14, train acc: 0.8375137448310852, train pre: 0.8419685363769531\n",
      "STARTING TRAINING FOR derivativedivides\n",
      "epoch: 0, train acc: 0.83599454164505, train pre: 0.5611672401428223\n",
      "epoch: 1, train acc: 0.8727131485939026, train pre: 0.6586124897003174\n",
      "epoch: 2, train acc: 0.8848772644996643, train pre: 0.6848219633102417\n",
      "epoch: 3, train acc: 0.8951451182365417, train pre: 0.7117561101913452\n",
      "epoch: 4, train acc: 0.901092529296875, train pre: 0.7230322360992432\n",
      "epoch: 5, train acc: 0.90826815366745, train pre: 0.7434480786323547\n",
      "epoch: 6, train acc: 0.911403477191925, train pre: 0.7503020763397217\n",
      "epoch: 7, train acc: 0.9152283072471619, train pre: 0.7603493928909302\n",
      "epoch: 8, train acc: 0.9188699722290039, train pre: 0.7680606245994568\n",
      "epoch: 9, train acc: 0.9217036366462708, train pre: 0.7747618556022644\n",
      "epoch: 10, train acc: 0.9240847229957581, train pre: 0.7811684012413025\n",
      "epoch: 11, train acc: 0.9265196919441223, train pre: 0.7876907587051392\n",
      "epoch: 12, train acc: 0.928674578666687, train pre: 0.792227029800415\n",
      "epoch: 13, train acc: 0.9319283962249756, train pre: 0.8018401861190796\n",
      "epoch: 14, train acc: 0.9332966804504395, train pre: 0.80596923828125\n",
      "STARTING TRAINING FOR parts\n",
      "epoch: 0, train acc: 0.8228499889373779, train pre: 0.7133264541625977\n",
      "epoch: 1, train acc: 0.8468226790428162, train pre: 0.7111884951591492\n",
      "epoch: 2, train acc: 0.8619927763938904, train pre: 0.7386807203292847\n",
      "epoch: 3, train acc: 0.8754498362541199, train pre: 0.7666800022125244\n",
      "epoch: 4, train acc: 0.8851466178894043, train pre: 0.785446286201477\n",
      "epoch: 5, train acc: 0.8912771940231323, train pre: 0.7964039444923401\n",
      "epoch: 6, train acc: 0.8979679942131042, train pre: 0.8083655834197998\n",
      "epoch: 7, train acc: 0.9019113779067993, train pre: 0.8155363202095032\n",
      "epoch: 8, train acc: 0.9065442681312561, train pre: 0.826160192489624\n",
      "epoch: 9, train acc: 0.9104660749435425, train pre: 0.832679808139801\n",
      "epoch: 10, train acc: 0.9129226207733154, train pre: 0.8383901119232178\n",
      "epoch: 11, train acc: 0.9164242744445801, train pre: 0.8443703651428223\n",
      "epoch: 12, train acc: 0.9195272326469421, train pre: 0.8486036658287048\n",
      "epoch: 13, train acc: 0.9213050007820129, train pre: 0.8502347469329834\n",
      "epoch: 14, train acc: 0.923653781414032, train pre: 0.8542875647544861\n",
      "STARTING TRAINING FOR risch\n",
      "epoch: 0, train acc: 0.7168745994567871, train pre: 0.7249546647071838\n",
      "epoch: 1, train acc: 0.756222128868103, train pre: 0.7521361708641052\n",
      "epoch: 2, train acc: 0.7876182198524475, train pre: 0.7902239561080933\n",
      "epoch: 3, train acc: 0.807927668094635, train pre: 0.8110538721084595\n",
      "epoch: 4, train acc: 0.8159114122390747, train pre: 0.822370707988739\n",
      "epoch: 5, train acc: 0.8287435173988342, train pre: 0.835525393486023\n",
      "epoch: 6, train acc: 0.8395823836326599, train pre: 0.8473496437072754\n",
      "epoch: 7, train acc: 0.8447216749191284, train pre: 0.8517748713493347\n",
      "epoch: 8, train acc: 0.8512077927589417, train pre: 0.8574880957603455\n",
      "epoch: 9, train acc: 0.855183482170105, train pre: 0.8611111044883728\n",
      "epoch: 10, train acc: 0.8621544241905212, train pre: 0.8697757124900818\n",
      "epoch: 11, train acc: 0.8644062280654907, train pre: 0.8732602596282959\n",
      "epoch: 12, train acc: 0.8682634234428406, train pre: 0.8768932223320007\n",
      "epoch: 13, train acc: 0.8739737272262573, train pre: 0.8822174072265625\n",
      "epoch: 14, train acc: 0.8764841556549072, train pre: 0.8833383321762085\n",
      "STARTING TRAINING FOR norman\n",
      "epoch: 0, train acc: 0.7817031741142273, train pre: 0.6501557230949402\n",
      "epoch: 1, train acc: 0.8422328233718872, train pre: 0.7201381921768188\n",
      "epoch: 2, train acc: 0.8583188056945801, train pre: 0.7472888827323914\n",
      "epoch: 3, train acc: 0.8680910468101501, train pre: 0.7685547471046448\n",
      "epoch: 4, train acc: 0.8755144476890564, train pre: 0.7839876413345337\n",
      "epoch: 5, train acc: 0.8821406364440918, train pre: 0.7980132699012756\n",
      "epoch: 6, train acc: 0.8877971172332764, train pre: 0.8103306293487549\n",
      "epoch: 7, train acc: 0.8915896415710449, train pre: 0.8177068829536438\n",
      "epoch: 8, train acc: 0.8956946134567261, train pre: 0.8262274265289307\n",
      "epoch: 9, train acc: 0.899228572845459, train pre: 0.8314880132675171\n",
      "epoch: 10, train acc: 0.9013833999633789, train pre: 0.8356778025627136\n",
      "epoch: 11, train acc: 0.9046264290809631, train pre: 0.842519998550415\n",
      "epoch: 12, train acc: 0.9065334796905518, train pre: 0.846156895160675\n",
      "epoch: 13, train acc: 0.9087745547294617, train pre: 0.8481429219245911\n",
      "epoch: 14, train acc: 0.9108539819717407, train pre: 0.8524622321128845\n",
      "STARTING TRAINING FOR trager\n",
      "epoch: 0, train acc: 0.979324221611023, train pre: 0.0\n",
      "epoch: 1, train acc: 0.9801538586616516, train pre: 0.6266666650772095\n",
      "epoch: 2, train acc: 0.9830305576324463, train pre: 0.7114673256874084\n",
      "epoch: 3, train acc: 0.9844527840614319, train pre: 0.739656925201416\n",
      "epoch: 4, train acc: 0.9849376082420349, train pre: 0.7719665169715881\n",
      "epoch: 5, train acc: 0.9854224324226379, train pre: 0.7927461266517639\n",
      "epoch: 6, train acc: 0.9857349395751953, train pre: 0.8152866363525391\n",
      "epoch: 7, train acc: 0.9861658811569214, train pre: 0.8208501935005188\n",
      "epoch: 8, train acc: 0.9866399168968201, train pre: 0.7863175868988037\n",
      "epoch: 9, train acc: 0.9868769645690918, train pre: 0.769645631313324\n",
      "epoch: 10, train acc: 0.9870493412017822, train pre: 0.7663690447807312\n",
      "epoch: 11, train acc: 0.987501859664917, train pre: 0.75\n",
      "epoch: 12, train acc: 0.9883207082748413, train pre: 0.7761589288711548\n",
      "epoch: 13, train acc: 0.9886439442634583, train pre: 0.7762148380279541\n",
      "epoch: 14, train acc: 0.9885469675064087, train pre: 0.7643784880638123\n",
      "STARTING TRAINING FOR parallelrisch\n",
      "epoch: 0, train acc: 0.7293511629104614, train pre: 0.6103740334510803\n",
      "epoch: 1, train acc: 0.7698407769203186, train pre: 0.6627234220504761\n",
      "epoch: 2, train acc: 0.7873488664627075, train pre: 0.7002236247062683\n",
      "epoch: 3, train acc: 0.7995560765266418, train pre: 0.7251763343811035\n",
      "epoch: 4, train acc: 0.8096084594726562, train pre: 0.7461828589439392\n",
      "epoch: 5, train acc: 0.8186588287353516, train pre: 0.7601316571235657\n",
      "epoch: 6, train acc: 0.82630854845047, train pre: 0.7727711796760559\n",
      "epoch: 7, train acc: 0.8341737389564514, train pre: 0.7860491871833801\n",
      "epoch: 8, train acc: 0.8407675623893738, train pre: 0.794241726398468\n",
      "epoch: 9, train acc: 0.8463054895401001, train pre: 0.8015366792678833\n",
      "epoch: 10, train acc: 0.8508091568946838, train pre: 0.8070845603942871\n",
      "epoch: 11, train acc: 0.8537720441818237, train pre: 0.8107589483261108\n",
      "epoch: 12, train acc: 0.860689103603363, train pre: 0.8211798071861267\n",
      "epoch: 13, train acc: 0.8614864349365234, train pre: 0.8223785161972046\n",
      "epoch: 14, train acc: 0.8651819825172424, train pre: 0.827584981918335\n",
      "STARTING TRAINING FOR meijerg\n",
      "epoch: 0, train acc: 0.9900014996528625, train pre: 0.0\n",
      "epoch: 1, train acc: 0.9900014996528625, train pre: 0.0\n",
      "epoch: 2, train acc: 0.9900445938110352, train pre: 0.5476190447807312\n",
      "epoch: 3, train acc: 0.9908526539802551, train pre: 0.6680850982666016\n",
      "epoch: 4, train acc: 0.9913590550422668, train pre: 0.6607142686843872\n",
      "epoch: 5, train acc: 0.991714596748352, train pre: 0.673202633857727\n",
      "epoch: 6, train acc: 0.9922640919685364, train pre: 0.6888489127159119\n",
      "epoch: 7, train acc: 0.9925442337989807, train pre: 0.6921824216842651\n",
      "epoch: 8, train acc: 0.9932876229286194, train pre: 0.741679847240448\n",
      "epoch: 9, train acc: 0.9935570359230042, train pre: 0.7546296119689941\n",
      "epoch: 10, train acc: 0.9938479065895081, train pre: 0.7628865838050842\n",
      "epoch: 11, train acc: 0.9939233064651489, train pre: 0.7749244570732117\n",
      "epoch: 12, train acc: 0.9943435192108154, train pre: 0.7976366281509399\n",
      "epoch: 13, train acc: 0.9942573308944702, train pre: 0.7874817848205566\n",
      "epoch: 14, train acc: 0.9946451783180237, train pre: 0.7980636358261108\n",
      "STARTING TRAINING FOR gosper\n",
      "epoch: 0, train acc: 0.8457344770431519, train pre: 0.47076642513275146\n",
      "epoch: 1, train acc: 0.8813433051109314, train pre: 0.6372097134590149\n",
      "epoch: 2, train acc: 0.8936798572540283, train pre: 0.6742411255836487\n",
      "epoch: 3, train acc: 0.9035167098045349, train pre: 0.7128196358680725\n",
      "epoch: 4, train acc: 0.9109832644462585, train pre: 0.73980712890625\n",
      "epoch: 5, train acc: 0.9171353578567505, train pre: 0.760845959186554\n",
      "epoch: 6, train acc: 0.9220914840698242, train pre: 0.7709226012229919\n",
      "epoch: 7, train acc: 0.924138605594635, train pre: 0.7771700024604797\n",
      "epoch: 8, train acc: 0.9279527068138123, train pre: 0.7900552749633789\n",
      "epoch: 9, train acc: 0.930182933807373, train pre: 0.794731855392456\n",
      "epoch: 10, train acc: 0.9317559599876404, train pre: 0.7962414026260376\n",
      "epoch: 11, train acc: 0.9332428574562073, train pre: 0.7982266545295715\n",
      "epoch: 12, train acc: 0.9360872507095337, train pre: 0.807692289352417\n",
      "epoch: 13, train acc: 0.9372292757034302, train pre: 0.8046910166740417\n",
      "epoch: 14, train acc: 0.9383390545845032, train pre: 0.8094232678413391\n"
     ]
    }
   ],
   "source": [
    "for algo in sub_algos:\n",
    "    print(f'STARTING TRAINING FOR {algo}')\n",
    "    data = SyntheticDataset(algo, edge_df, graph_df)\n",
    "    data = create_dataloaders(data, size=256)\n",
    "    class_model = train(data)\n",
    "    \n",
    "    # Save model\n",
    "    th.save(class_model.state_dict(), 'Models/TreeLSTM/Small Data/' + algo + '.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df4d7f",
   "metadata": {},
   "source": [
    "# Format the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f72478",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_data, columns=['integrand', 'prefix', 'integral', 'label'])\n",
    "test_df['graph_id'] = range(len(test_df))\n",
    "\n",
    "test_df['prefix'] = test_df['prefix'].apply(replace_int_with_C)\n",
    "\n",
    "test_df['label'] = test_df['label'].apply(change_to_binary)\n",
    "\n",
    "graph_specs = test_df.swifter.apply(make_graph_df, axis=1)\n",
    "\n",
    "edges = [x[0] for x in graph_specs]\n",
    "graphs= [x[1] for x in graph_specs]\n",
    "\n",
    "test_edges = pd.concat(edges).reset_index(drop=True)\n",
    "test_graphs = pd.concat(graphs).reset_index(drop=True)\n",
    "test_graphs.set_index('graph_id', drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a22dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_algos = [\"default\",\n",
    "\"derivativedivides\",\n",
    "\"parts\",\n",
    "\"risch\",\n",
    "\"norman\",\n",
    "\"trager\",\n",
    "\"parallelrisch\",\n",
    "\"meijerg\",\n",
    "\"gosper\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_dict = {}\n",
    "for algo in sub_algos:\n",
    "    model = TreeLSTM(vocab_size,\n",
    "                    x_size, \n",
    "                    hidden_size, \n",
    "                    num_classes,\n",
    "                    dropout\n",
    "                )\n",
    "    model.load_state_dict(th.load('Models/TreeLSTM/' + algo + '.pth'))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Create dataset for model\n",
    "    test_data = SyntheticDataset(algo, test_edges, test_graphs)\n",
    "    test_data = create_dataloaders(test_data, size=256)\n",
    "\n",
    "\n",
    "    model_dict[algo] = (model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004507ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for model_name, model_data_pair in model_dict.items():\n",
    "    print(str(model_name))\n",
    "    all_results.append( test(model_data_pair[0], model_data_pair[1]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1751b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.dumps(all_results)\n",
    "with open('Probabilities/Test Data/TreeLSTM_probs.json', 'w') as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7964fb20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
